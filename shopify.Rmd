---
title: "Shopify"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}
#import the dataset
library(readr)
library(Hmisc)
library(ggplot2)
library(dplyr)
shopify <- read_csv("Downloads/shopify.csv")
```

# Question 1

```{r}
summary(shopify$order_amount)
sd(shopify$order_amount)
```

We see that the mean is 3145, while the median is 284 and standard deviation is 41282.54, which is quite large comparing to the mean. While the third quartile is at 390, the maximum is at 704000. The gap between the two numbers is huge. Those could be the reason why the calculation could gone wrong. 

```{r}
#check if there's any missing value in the dataset
which(is.na(shopify))
#check for values larger than 3145
sample(shopify[which(shopify$order_amount > 3145),],5)
unique(shopify[which(shopify$order_amount > 3145),]$shop_id)
```

We can see that shop_id 42 and 78 are the two main stores that may cause outlier in our dataset. 

```{r}
shop42 = as.data.frame(shopify[which(shopify$shop_id == 42),])
ggplot(shop42, aes(y = order_amount, x = order_id, color=total_items))+ geom_point() + ggtitle("Order Amount for shop_id = 42") 
shop78 = as.data.frame(shopify[which(shopify$shop_id == 78),])
ggplot(shop78, aes(y = order_amount, x = order_id, color=total_items))+ geom_point() + ggtitle("Order Amount for shop_id = 78") 
```

We could see from the table and graph that shop42 usually sells a bulk order of items (e.g. 2000 items with total of 704000), while shop78 usually sells a few items (e.g. 1 item with total of 25725).

```{r}
shop42 %>%
  group_by(total_items) %>%
  summarise(total=sum(order_amount))
shop78 %>%
  group_by(total_items) %>%
  summarise(total=sum(order_amount))

```

Therefore, these relatively "few" or "massive" observations generated by store ID: 42 and 78 skew the distribution order_amount. Some better ideas on evaluating the data would be divide the groups up into different regions based on the order_amount. For example, larger than 3000 and smaller than 500, etc. Or we could evaluate based on the total_items sold.


We need to get a better understanding of what the shopify managers want to know from the dataset and what are the important factors we should highlight from the analysis. However, it is always imporrant to note that we cannot be looking at a single metric in isolation, as it can be extremely misleading.

```{r}
shopify %>%
  group_by(total_items) %>%
  summarise(total=sum(order_amount),
            mean=mean(order_amount),
            median = median(order_amount),
            `standard deviation` = sd(order_amount))
```

Dividing up the dataset based on total_items could give us a clearer idea of what we might want. Also, the median could provide additional information about the order_amount, allowing store managers to better understand the evaluation. Some important thing to note is that there's only 1 order with total_item of 8, so the sd is NA. All order_amouont for total_items of 2000 is the same, so the sd is 0.

# Question 2

## part a
![There are total of 54 orders shipped by Speedy Express.](/Users/ray/Desktop/1.png)

## part b
![The last name of the employee with most orders is Peacock.](/Users/ray/Desktop/2.png)

## part c
![The product named Steeleye Stout was ordered most by customers in Germany.](/Users/ray/Desktop/3.png)




